\documentclass[11pt,a4paper]{amsart}
\usepackage[slovene]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{url}
\usepackage{enumerate}
\usepackage{titlesec}
\titleformat*{\section}{\sc\bfseries\centering}

\usepackage[
top    = 0.9cm,
bottom = 0.9cm,
left   = 1cm,
right  = 1cm]{geometry}

% ukazi za matematicna okolja
\theoremstyle{definition} % tekst napisan pokoncno
\newtheorem{definicija}{Definicija}[section]
\newtheorem{primer}[definicija]{Primer}
\newtheorem{opomba}[definicija]{Opomba}
\newtheorem{zgled}[definicija]{Zgled}

\theoremstyle{plain} % tekst napisan posevno
\newtheorem{lema}[definicija]{Lema}
\newtheorem{izrek}[definicija]{Izrek}
\newtheorem{trditev}[definicija]{Trditev}
\newtheorem{posledica}[definicija]{Posledica}


\newenvironment{itemize*}%
{
\vspace{-6pt}
\begin{itemize}
\setlength{\itemsep}{0pt}
\setlength{\parskip}{1pt}
}
{\end{itemize}}

\newenvironment{enumerate*}%
{
\vspace{-6pt}
\begin{enumerate}
\setlength{\itemsep}{0pt}
\setlength{\parskip}{1pt}
}
{\end{enumerate}}

\newcommand{\ds}{\ensuremath{\,\mathrm{d}s}}
\newcommand{\dx}{\ensuremath{\,\mathrm{d}x}}
\newcommand{\dxi}{\ensuremath{\,\mathrm{d}\xi}}
\newcommand{\dy}{\ensuremath{\,\mathrm{d}y}}
\newcommand{\dt}{\ensuremath{\,\mathrm{d}t}}
\newcommand{\dd}[1]{\ensuremath{\,\mathrm{d}#1}}
\let\oldint\int
\renewcommand{\int}{\oldint \!}


\newcommand{\R}{\mathbb R}
\newcommand{\N}{\mathbb N}
\newcommand{\Q}{\mathbb Q}
\newcommand{\F}{\mathcal{F}}
\newcommand{\Cont}{\mathcal{C}}

\newcommand{\X}{\underline{X}}
\newcommand{\Y}{\underline{Y}}
\newcommand{\Z}{\underline{Z}}
\newcommand{\W}{\underline{W}}
\newcommand{\uu}{\underline{u}}
\newcommand{\ux}{\underline{x}}
\newcommand{\utheta}{\underline{\vartheta}}
\newcommand{\uv}{\underline{v}}
\newcommand{\ubeta}{\ensuremath{\underline{\beta}}}
\newcommand{\ueps}{\ensuremath{\underline{\varepsilon}}}
\DeclareMathOperator{\cov}{cov}
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\corr}{corr}
\DeclareMathOperator{\se}{se}

\pagestyle{empty}

\begin{document}
\thispagestyle{empty}
\setlength{\parindent}{0pt}

% \fontsize{9pt}{9pt}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

$\X = \left( \begin{matrix}
  X_1 \\ X_2 \\ \vdots \\ X_n
\end{matrix} \right)
 \longrightarrow E(\X) = \left( \begin{matrix} E(X_1) \\ E(X_2) \\ \vdots \\ E(X_n) \end{matrix} \right)
 \longrightarrow \cov(\X) = \left(
 \begin{matrix}
 \var(X_1)  & \cov(X_1,X_2) & \cdots & \cov(X_1,X_n) \\
 \cov(X_2,X_1) & \var(X_2) & \cdots & \cov(X_2, X_n) \\
 \vdots  & \vdots & \ddots & \vdots \\
 \cov(X_n, X_1) & \cov(X_n,X_2) & \cdots & \var(X_n)
 \end{matrix}   \right)$

 kovariančna matrika (simetrična, pozitivno semi-definitna)

 $\uu \otimes \uv = \uu\uv^T$

 $\X \X^T =  \left(
 \begin{matrix}
 X_1^2  &X_1X_2 & \cdots &X_1X_n \\
 X_2X_1 & X_2^2 & \cdots & X_2 X_n \\
 \vdots  & \vdots & \ddots & \vdots \\
 X_n X_1 & X_nX_2 & \cdots & X_n^2
 \end{matrix}   \right)$

 $\cov(\X) = E[(\X-E(\X))(\X - E(\X))^T] = E(\X\X^T) - E(\X)E(\X)^T$

korelacijski koeficient: $\corr(X_1,X_2) = \frac{\cov(X_1,X_2}{\sqrt{\var(X_1)
\var(X_2)}}$

 Če je $A$ deterministična matrika (konstantna), velja: $E(A\X) = A E(\X)$,
 $\cov(A\X) = A\cov(\X)A^T$

 $\cov(\langle \X, \uu \rangle , \langle \X, \uv \rangle) =
 \rangle \cov(\X)\uu,\uv \rangle$, $\cov (\uu^T
 \X, \uv^T \X) = \uv^T \cov(\X) \uu$

Standardna $p$-razsežna normalna porazdelitev je porazdelitev slučajnega
vektorja $ \left( Z_1 ,  Z_2 , \ldots , Z_n  \right)$,

  kjer so $Z_1, \ldots , Z_p \sim N(0,1)$ in neodvisne.

Če je $Q$ ortogonalna matrika in $\Z$ standarden normalen vektor,
potem je $\W = Q\Z$ tudi standarden normalen.

Splošna $n$-razsežna normalna porazdelitev je vsaka porazdelitev slučajnega
vektorja $\W = A\Z+\uu$, kjer je $\Z$
standarden $p$-razsežni normalni vektor, $A$ matrika $n \times p$ polnega ranga
in $\uu \in \R^n$.

$E(\Z) = 0$, $\cov(\Z) = I$, $E(\underline{W}) =
\uu$, $\cov(\Z) = AA^T$

Če $A \in \R^{n\times p}$ polnega ranga, je $AA^T$ polnega ranga (in obrnljiva).

$\sigma > 0, X \sim N(\mu, \sigma^2 ) \Longrightarrow P(X \leq a ) = \Phi
(\frac{a-\mu}{\sigma})$

$X_1,\ldots, X_n \sim N(\mu, \sigma^2)$, potem $X_1  + \cdots +  X_n \sim N(n\mu, \frac{\sigma^2}{n})$, $\overline{X} \sim N(\mu, \sigma^2)$, $\overline{X} - \mu \sim N(0, \frac{\sigma^2}{n})$

\textbf{Pogojna gostota}: $f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_y (y)}$

$\left( \begin{matrix} X_1 \\ X_2 \end{matrix} \right)
\sim
N \left(
\left[ \begin{matrix} \mu_1 \\ \mu_2 \end{matrix} \right],
\left[ \begin{matrix} \Sigma_{11} & \Sigma_{12} \\ \Sigma_{21} & \Sigma_{22} \end{matrix} \right] \right)
\Longrightarrow
X_2 | X_1 \sim N(\mu_2 +  \Sigma_{21}\Sigma_{11}^{-1} (X_1 - \mu_1), \Sigma_{22} - \Sigma_{21} \Sigma_{11}^{-1} \Sigma_{12} )$

$||X||^2 = X^T X = sl(XX^T)$

Če poznamo porazdelitev slučajne spremenljivke $Y$ in $f_{X|Y}$, potem velja
$f_X(x) = E[f_{X|Y}(x)]$.

\textbf{Pogojne pričakovane vrednosti}: $E(X) = E[E(X|Y)]$, $ \quad E[Xg(Y)|Y] =
E(X|Y)g(X)$, v abstraktnem smislu definiramo $E[Y|X]$ kot funkcijo $\Psi(x)$, za katero
za vsako omejeno zvezno funkcijo $g$ velja $E[Yg(x)]=E[\Psi(x)g(x)]$.

$\cov(X,Y) = \cov(E(X|Z),E(Y|Z)) + E(\cov(X,Y|Z))$, med drugim $\var(X) =
\var(E(X|Z)) + E(\var(X|Z))$

Če so $X_1,\ldots , X_n$ neodvisne med seboj in tudi od $Y_1,\ldots , Y_n)$,
potem so $X_1,\ldots, X_n$ neodvisne tudi pogojno na $Y$.

\section*{Centralni limitni izrek}

\textbf{Izrek}: Naj bodo $X_1,X_2, \ldots$ neodvisne, enako porazdeljene z
$E(X_i^2) < \infty$ in $E(X_i) = \mu_1$ ter $\var(X_i) = \sigma_1^2$. $S_n = X_1
+ X_2 + \cdots X_n$. Tedaj:
$$
\frac{S_n - n\mu_1}{\sigma_1 \sqrt{n} } \xrightarrow[n\rightarrow \infty]{\text{šibko}} N(0,1),
$$
kjer $n\mu_1 = E(S_n)$ in $\sigma_1 \sqrt{n} = \sigma(S_n)$.

Bolj ohlapno: $n$ velik $\Longrightarrow S_n \dot{\sim} N(n\mu_1, n\sigma^2)$

$P(a \leq S_n \leq b) \approx \Phi(\frac{b-n\mu_1}{\sigma_1\sqrt{n}}) - \Phi
(\frac{a-n\mu_1}{\sigma_1 \sqrt{n}})$

Če slučajna spremenljivka živi v celih številih, lahko namesto $\leq$ vzamemo
$<$ in mejo povečamo za 1, ali pa vzamemo sredino.

Natančnost sredine je odvisna od asimetrije, ki jo meri $A(X) =
\frac{E[(X-E(X))^3]}{(\var(X))^{ \frac{3}{2}}}$.

Naj bodo $X_1,\ldots, X_n$ neodvisne in identično porazdeljene, $\sigma_1 =
\sqrt{\var(X_i)}$, $\gamma_1 = E[|X_i - E(X_i) |^3]^{\frac{1}{3}}$, $S_n = X_1
+ \cdots + X_n$. Ko $n \longrightarrow \infty$, $P(a_n \leq S_n \leq b_n)$
aproksimiramo z ustreznimi normalnimi. Zadosten pogoj, da gre:

\begin{itemize}
\item absolutna napaka $\rightarrow 0$: $n \gg \frac{\gamma_1^6}{\sigma_1^6}$
\item relativna napaka $\rightarrow 0$: $n \gg \frac{\gamma_1^6}{\sigma_1^6}$ in $\min \{ |a_n - E(S_n)|, |b_n - E(S_n)| \} \ll \frac{n^{\frac{2}{3}}\sigma_1^2}{\gamma_1}$
\end{itemize}

$\mu_1 = E(X_i)$, $\sup_{x\in \R} |P(S_n \leq x) - \Phi(
\frac{x-n\mu_1}{\sigma_1 \sqrt{n}} )| \leq \frac{0.4774}{\sqrt{n}}
\frac{\gamma_1^3}{\sigma_1^3}$

\textbf{Porazdelitev $\chi^2$}:

Če so $Z_1,\ldots ,Z_n$ neodvisne standardno normalne, potem je $Z_1^2 + \cdots
+ Z_n^2 \sim \chi^2(n)$, $\chi^2 (n) \xrightarrow{n\rightarrow \infty} N(0,1)$.

$\chi^2(n) = \Gamma(\frac{n}{2}, \frac{1}{2})$

Če $U \sim \Gamma(a,\lambda)$ in $V \sim \Gamma(b, \lambda)$, potem $U+V \sim
\Gamma (a+b, \lambda)$

Če $U_1,\ldots , U_m \sim \Gamma(\frac{n}{2m},\frac{1}{2})$ neodvisne, potem
$U_1 + \cdots + U_m \sim \chi^2 (n)$.

\textbf{Razmerje Ljapunova}:

$S= X_1+\cdots + X_n$, $\mu = E(S)$, $\sigma^2 = \var(S)$, $X_1,\ldots , X_n$
neodvisne.  $P(a \leq S \leq b) \approx \Phi(\frac{b-\mu}{\sigma}) - \Phi
(\frac{a-\mu}{\sigma})$

$\sup_{x\in \R} |P(S\leq x) - \Phi (\frac{x-\mu}{\sigma})| \leq
\frac{0.5591}{\sigma^3} \sum_{k=1}^n E[|X_k - E(X_k)|^3]$

Če desna stran konvergira k 0, imamo konvergenco k $N(0,1)$.

\section*{Dejanska statistika -- vzročenje}

$\widehat{a}$ je \underline{nepristranska cenilka} za $a$, če je $E(\widehat{a}) = a$,
\underline{srednja kvadratična napaka}: $q(\widehat{a}) = E[(\widehat{a}-a)^2]$,
\underline{standardna napaka}: $\sqrt{q(\widehat{a})} = se(\widehat{a})$.

Slučajne spremenljivke $X_1,\ldots ,X_n$ so \underline{izmenljive}, če velja:
$(X_{\pi(1)},X_{\pi(2)},\ldots, X_{\pi(n)}) \stackrel{d}{=} (X_1,X_2,\ldots,X_n)
\quad \forall \pi \in S_n.$

Za izmenljive sl. spr. $X_1,\ldots ,X_n$ s pričakovano vrednosti $E(X_i) = \mu$,
varianco $\var(X_i) = \sigma^2$, korelacijo $\corr(X_i, X_j) = \rho$, za $i \neq
j$ je vzorčno povprečje $\overline{X} = \frac{X_1 + \cdots + X_n}{n}$ nepristranska
cenilka za $\mu$,  $\var(\overline{X}) = \frac{\sigma^2}{n}(1+\rho(n+1))$,
nepristranska cenilka za $\sigma^2$ pa je $\hat{\sigma}^2 =
\frac{1}{(n-1)(1-\rho)}\sum_{i=1}^n (X_i - \overline{X})^2 $

\textbf{Enostavno slučajno vzorčenje}

Populacija: $1,2,\ldots , N$, vzorec: $K_1, K_2, \ldots, K_n$. Vrednosti
spremenljivk na populaciji $x_1, x_2, \ldots, x_N$ (ne poznamo vseh). Poznamo
vrednosti na vzorcu: $X_i = x_{K_i}$ (izmenljive, ker je vsaka $n$-terica enako
verjetna)

\textbf{Stratificirano vzorčenje}:

Populacijo velikosti $N$ razdelimo na $k$ stratumov velikosti $N_1,\ldots,N_k$,
kjer $w_1,w_2,\ldots ,w_k$ ($w_i = \frac{N_i}{N}$ in $w_1 + \cdots + w_k = 1$)
predstavljajo delež populacije v stratumih, $\mu_1,\ldots, \mu_k$ povprečja
stratificiranih spremenljivk, $\sigma_1,\ldots,\sigma_k$ standardne odklone.
Povprečje na celotni populaciji je $\mu = w_1\mu_1 + \cdots + w_k\mu_k$.

Varianca na celi populaciji: $\sigma^2 = \sigma_B^2 + \sigma_w^2$, kjer $\sigma_B^2 = \sum_{i=1}^k w_i(\mu_i - \mu)^2$ in $\sigma_w^2 = \sum_{i=1}^k w_i \sigma_i^2$.

Enostavni slučajni vzorci po stratumih:

$
\begin{matrix}
X_{11},\ldots ,X_{1n_1} & \overline{X}_1 \\
X_{21}, \ldots ,X_{2n_2} & \overline{X}_2 \\
\vdots & \vdots \\
X_{k1},\ldots , X_{kn_k} & \overline{X}_k
\end{matrix}
$,
kjer so $\overline{X}_i$ vzorčna povprečja po stratumih. $\overline{X} =
\sum_{i=1}^k w_i \overline{X}_i$ je nepristranska cenilka za $\mu$,

$\sigma_i^2 = \frac{1}{n_i - 1} \frac{N_i -1}{N_i} \sum_{j=1}^{n_i} (X_{ij} -
\overline{X}_i)^2$ nepristranska cenilka za $\sigma_i^2$, $\widehat{\sigma}_w^2
= \sum_{i=1}^k \frac{w_i}{n_i - 1} \frac{N_i-1}{N_i}\sum_{j=1}^{n_i} (X_{ij} -
\overline{X}_i)^2$  nepristranska cenilka za $\sigma_w^2$ in
$\widehat{\sigma}_B^2 = \sum_{i=1}^k w_i (\overline{X}_i - \overline{X})^2 -
\sum_{i=1}^k (w_i - w_i^2) \frac{N_i - n_i}{N_i - 1}\frac{1}{n_i}
\widehat{\sigma}_i^2$ nepristranska cenilka za $\sigma_B^2$.

\section*{intervali zaupanja}

$a$ bi radi ocenili: $a_{min} < a < a_{max}$, kjer je $(a_{min},a_{max})$
interval zaupanja. $P(a_{min} < a < a_{max}) \geq 1-\alpha$, kjer je $1-\alpha$
stopnja zaupanja $(95\%, 99\%)$ in $\alpha$ stopnja tveganja $(5\%, 1\%)$.

Določanje IZ: pivotna funkcija $T(\X , a)$, kjer je $\X$ opažanje in $a$
ocenjevani parameter.

IZ za $\mu$, kjer je $\sigma$ znan: $P(|\overline{X} - \mu| < M_\alpha ) =
1-\alpha$, $M_\alpha = \frac{\sigma}{\sqrt{n}} \Phi^{-1}(1-\frac{\alpha}{2})$

Če tudi $\sigma$ ne poznamo in če so $X_1,\ldots, X_n \sim N(\mu, \sigma^2)$,
potem $T(\X ,\mu) = \frac{\overline{X} - \mu}{S^2}\sqrt{n}$, kjer $S^2 =
\frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2$. Za velike $n$ je $
\frac{\overline{X} - \mu}{S}\sqrt{n} \,\dot{\sim}\, N(0,1)$, v splošnem pa je $
\frac{\overline{X} - \mu}{S}\sqrt{n} \sim \text{Student}(n-1).$

\section*{Ocenjevanje parametrov}
\textbf{Metoda momentov:} \\
Vzorec $\ = (X_1, \dots, X_n)^T$ je iz neke porazdelitve $f_X(x|\utheta)$.
Nastavimo parametre $\utheta$, da bo povprečje enako vzorčnemu povprečju,
varianca vzorčni varianci\dots. Rešimo sistem enačb: $E[X] = \bar{X}$, $\var(X)
= \frac{1}{n-1}\sum_{i=1}^n (X_i - \bar{X})^2$.

\textbf{Metoda največjega verjetja}: Postavimo se na stališče, da je vzorec
$\ux = (x_1, \dots, x_n)^T$ neke porazdelitve
$f_X(x|\utheta)$, ki smo ga dobili verjetno eden izmed bolj verjetnih,
in nastavimo parametre $\utheta$ tako, da bo najbolj verjeten.
Kako verjeten je vzorec je podano s funkcijo verjetja $L$.
Če so vzorci neodvisni, je $L(\utheta|\ux) = \prod_{i=1}^n f_X(x_i|\utheta)$. V
diskretnem primeru je to $L(\utheta|\ux) = \prod_{i=1}^n P_{\utheta}(X=x_i)$. \\
Definiramo tudi logaritemsko funkcijo verjetja $\ell(\utheta|\ux) =
\log(L(\utheta|\ux))$.

Cenilka po metodi največjega verjetja (MLE) je vrednost $\hat{\utheta}$, kjer je
dosežen maksimum $L$, ali ekvivalentno, $\ell$. Cenilka je nepristranska.
Ponavadi jo dobimo tako da rešimo sistem $\frac{\partial \ell}{\partial
\utheta}(\utheta|\ux) = 0$ za $\utheta$. \\
Za MLE velja: $\sqrt{n}(\vartheta - \hat{\utheta}) \,\dot{\sim}\, N(0, I^{-1}(\utheta))$.

\textbf{Fisherjeva matrika informacije:} \\
Varianca MLE je dana s Fisherjevo matriko informacije. \\
Matrike je dana z $I_{kl}(\utheta) = -E\left[\frac{\partial^2}{\partial
\vartheta_k\partial\vartheta_l}(\log(f_X(x|\utheta)))\right]$, $I(\utheta) = -E[\text{hesse}(\log(f_X(x|\utheta)))]$.

Velja: $\var(\hat{\utheta}_k) = \frac{(I^{-1})_{kk}}{n}$, $\se(\hat{\utheta}_k) =
\sqrt{\frac{(I^{-1})_{kk}}{n}}$.

Za primer, ko je $\vartheta$ skalar, se formule poenostavijo:
$I(\vartheta) = E[\frac{\partial^2}{\partial\vartheta^2}
\log(f_X(x|\vartheta))]$, \\
$\se(\hat{\vartheta}) = \frac{1}{\sqrt{n I(\vartheta)}}$.
Aproksimativni interval zaupanja: $\vartheta \in \left( \hat{\vartheta} \pm z_{1-\frac{\alpha}{2}}
\sqrt{\frac{1}{nI(\hat{\vartheta})}}\right)$.

\section*{Testiranje hipotez}

\section*{Linearna regresija}
Predpostavljamo, da so opaženi slučajni podatki $\Y = (Y_1, \dots, Y_n)^T$ nastali kot
$\Y = X \ubeta + \ueps$, kjer je $X$ znana deterministična $n \times m$ matrika, $\ubeta$
neznan determinističen $m$ vektor, $\ueps$ neznan slučajen vektor napak, za katerega
predpostavimo standardni regresijski model, ki pravi: $E[\ueps] = 0$ in
$\var(\ueps) = \sigma^2 I$.  Drugače povedano, napake $\varepsilon_i$ so
nekorelirane, varianca vsake posamezne pa je $\sigma^2$.

Za $\ubeta = (\alpha, \beta)^T$ in $X = (1, x_1; 1, x_2; \dots; 1, x_n)$
preidemo na standardno ocenjevanje s premico.

Nepristranska cenilka za $\ubeta$ je cenilka po metodi najmanjših kvadratov
$\hat{\ubeta} = (X^TX)^{-1}X^TY$.

Varianca cenilke: $\var(\ubeta) = \sigma^2(X^TX)^{-1} = \sigma^2C$.

Nepristranska cenilka za $\sigma^2$ je $\hat{\sigma}^2 = \frac{1}{n-m}
\sum_{i=1}^n \hat{\ueps}_i^2$, kjer je $\hat{\ueps} = \Y - X\ubeta$.

Če gledamo samo posamezne komponente je cenilka za $\beta_i$ enaka
$\hat{\beta}_i = (\hat{\ubeta})_i$ in $\var(\hat{\beta}_i) = \sigma^2C_{ii}$,
$\se(\hat{\beta_i}) = \sigma \sqrt{C_{ii}}$.

Za lin. kombinacijo komponent je cenilka enaka $a^T\hat{\ubeta}$ in njena
varianca je $\var(a^T\hat{\ubeta}) = a^T C a$, za poljuben vektor $a$.

Izrek (Gauss-Markov): Cenilka po metodi najmanjših kvadratov je najboljša med
vsemi linearnimi nepristranskimi cenilkami (ima najmanjšo varianco). Za vsako
linearno cenilko $\tilde{\ubeta} = L\Y$ mora veljati $LX = I$ in posledično
$\var(\tilde{\ubeta}) = \var(\tilde{\ubeta} - \hat{\ubeta}) +
\var(\hat{\ubeta})$, saj je $\cov(\tilde{\ubeta} - \hat{\ubeta}, \hat{\ubeta}) =
0$. Enako velja tudi za cenilko $a^T\hat{\ubeta}$ za vsak vektor $a$, v posebnem
za $a = e_i$ tudi za cenilke po komponentah.

Če za $\ueps$ predpostavljamo $\var(\ueps) = \sigma^2\Sigma$ za neko pd.\
matriko $\Sigma$, potem to prevedemo na standardni model z množenjem z leve s
$(\Sigma)^{-\frac12}$. Cenilka za $\ubeta$ postane $\hat{\ubeta} =
(X^T\Sigma X)^{-1}X^T\Sigma^{-1} \Y$.

Za testiranje hipoteze $\beta_i = 0$ proti $\beta_i \neq 0$ uporabimo testno
statistiko $t = \frac{\hat{\ubeta}_i}{\hat{\sigma} \sqrt{C_{ii}}} \sim t_{n-m}$.

\end{document}
